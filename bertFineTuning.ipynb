{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install numpy\n",
        "!pip install evaluate\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFmC5To8OAB3",
        "outputId": "cba716c7-fc3d-4d73-9b11-0d663d079b34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a TensorFlow model with Keras\n",
        "You can also train 🤗 Transformers models in TensorFlow with the Keras API!\n",
        "\n",
        "## Loading data for Keras\n",
        "When you want to train a 🤗 Transformers model with the Keras API, you need to convert your dataset to a format that Keras understands. If your dataset is small, you can just convert the whole thing to NumPy arrays and pass it to Keras. Let’s try that first before we do anything more complicated.\n",
        "\n",
        "First, load a dataset. We’ll use the CoLA dataset from the GLUE benchmark, since it’s a simple binary text classification task, and just take the training split for now.\n"
      ],
      "metadata": {
        "id": "629xx0xzT57K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar el conjunto de datos IMDB Movie Review con una división específica\n",
        "dataset = load_dataset(\"imdb\", split=\"train[:1000]\")  # Cargar las primeras 1000 instancias del conjunto de entrenamiento\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento (80%) y validación (20%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ahora puedes utilizar estos conjuntos de datos en tu modelo\n",
        "# import pandas as pd\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Leer el archivo CSV y eliminar filas con valores NaN\n",
        "# df = pd.read_csv(\"/content/diseases_articles.csv\")\n",
        "# df = df.dropna()\n",
        "\n",
        "# # Dividir en entrenamiento (80%) y prueba (20%)\n",
        "# dataset_train, dataset_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Dividir el conjunto de entrenamiento en entrenamiento (75%) y validación (25%)\n",
        "# dataset_train, dataset_validation = train_test_split(dataset_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# # Convertir los DataFrames a conjuntos de datos de TensorFlow/Keras\n",
        "# dataset_train = tf.data.Dataset.from_tensor_slices((dataset_train['Sentence'].values, dataset_train['Disease Name'].values))\n",
        "# dataset_validation = tf.data.Dataset.from_tensor_slices((dataset_validation['Sentence'].values, dataset_validation['Disease Name'].values))\n",
        "# dataset_test = tf.data.Dataset.from_tensor_slices((dataset_test['Sentence'].values, dataset_test['Disease Name'].values))\n",
        "\n",
        "# # Ahora puedes usar estos conjuntos de datos en tu modelo de TensorFlow/Keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO_8KrzEUAKR",
        "outputId": "038dbb86-ce02-42e1-eee5-8422d817da5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBuXXVkKfx_Q",
        "outputId": "a07802bc-706f-4813-ff0e-6d7375d54f22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, load a tokenizer and tokenize the data as NumPy arrays. Note that the labels are already a list of 0 and 1s, so we can just convert that directly to a NumPy array without tokenization!"
      ],
      "metadata": {
        "id": "904cq014UDuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "#tokenirizamos training\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
        "tokenized_data = tokenizer(dataset_train[\"text\"], return_tensors=\"np\", padding=True)\n",
        "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
        "tokenized_data_train = dict(tokenized_data)\n",
        "\n",
        "labels_train = np.array(dataset_train[\"label\"])  # Label is already an array of 0 and 1\n",
        "\n",
        "#tokenirizamos test\n",
        "tokenized_data = tokenizer(dataset_test[\"text\"], return_tensors=\"np\", padding=True)\n",
        "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
        "tokenized_data_test = dict(tokenized_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07d12bw5UF8q",
        "outputId": "96ede6c9-cd95-4d7a-ecaf-d5fbf519932f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, load, compile, and fit the model. Note that Transformers models all have a default task-relevant loss function, so you don’t need to specify one unless you want to:"
      ],
      "metadata": {
        "id": "gA33gsXTUQVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load and compile our model\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\")\n",
        "# Lower learning rates are often better for fine-tuning transformers\n",
        "model.compile()  # No loss argument!\n",
        "\n",
        "model.fit(tokenized_data_train, labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mt0nEEziUSeb",
        "outputId": "4fb234f3-84b7-4d1f-bb39-2fcab634a340"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-6-e62ab28ab23b>\", line 9, in <cell line: 9>\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1229, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1669, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1672, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 588, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1738, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1750, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1738, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 973, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 607, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 613, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 506, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 390, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 307, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/regularization/dropout.py\", line 109, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/regularization/dropout.py\", line 120, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/control_flow_util.py\", line 106, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/control_flow_util.py\", line 109, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/regularization/dropout.py\", line 117, in dropped_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\", line 2157, in dropout\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\", line 2164, in dropout\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\", line 2176, in dropout\n\nOOM when allocating tensor with shape[32,12,1564,1564] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_38234]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e62ab28ab23b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# No loss argument!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_batch_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-6-e62ab28ab23b>\", line 9, in <cell line: 9>\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1229, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1669, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1672, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 588, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1738, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1750, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1738, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 973, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 607, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 613, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 506, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 390, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 307, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filep5_3jmgq.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/regularization/dropout.py\", line 109, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/regularization/dropout.py\", line 120, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/control_flow_util.py\", line 106, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/control_flow_util.py\", line 109, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/regularization/dropout.py\", line 117, in dropped_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\", line 2157, in dropout\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\", line 2164, in dropout\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\", line 2176, in dropout\n\nOOM when allocating tensor with shape[32,12,1564,1564] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_38234]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBQGXWXEYMkk",
        "outputId": "450408a0-aa99-49f9-9ed6-39d9b5944f12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "di3T5rSzV7Ge",
        "outputId": "68b7411d-e7f5-4d94-eb9f-7f85726233c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = model.evaluate(tokenized_data_test, labels_test, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "fF0vo8KjZQuw",
        "outputId": "7a7c8e00-1cda-48f4-a784-f4ca9b36bd17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'labels_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3ef06fe7dcf2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'labels_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicciones=model.predict(tokenized_data_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR184JEydqbk",
        "outputId": "725fb9cc-2117-4749-8066-789a4ef3ec6b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 3s 97ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test[\"label\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl8Ys25Pd2nI",
        "outputId": "a4e652ed-1852-4be0-97f7-0b265a2fd97c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}